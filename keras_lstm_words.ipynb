{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Embedding, RepeatVector, SharedDense\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "import theano\n",
    "theano.config.optimizer='fast_compile'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "filename = \"/media/charles/data/articles\"\n",
    "h = open(filename)\n",
    "all_jsons=[]\n",
    "for line in h:    \n",
    "    if line[0]=='[':\n",
    "        all_jsons.append(line[:-1])\n",
    "        \n",
    "TitleList = []\n",
    "#TextList = []\n",
    "IndexList = []\n",
    "count = 0\n",
    "\n",
    "for oneJson in all_jsons:\n",
    "    u = json.loads(oneJson)\n",
    "    for item in u:\n",
    "        fields = item['fields']\n",
    "        TitleList.append(fields['title'].encode('ascii','ignore'))\n",
    "        #TextList.append(fields['text'].encode('ascii','ignore'))\n",
    "        IndexList.append(item['rowKey'].encode('ascii','ignore'))\n",
    "        count+=1\n",
    "        if count%10000==0:\n",
    "            print(\"done: \"+str(count))\n",
    "\n",
    "all_jsons = []\n",
    "del all_jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import np_utils\n",
    "\n",
    "max_words = 10000\n",
    "batch_size = 16\n",
    "\n",
    "print \"Loading data...\"\n",
    "X_seq = TitleList[0:60000]\n",
    "\n",
    "print len(X_seq), 'total sequences'\n",
    "\n",
    "print \"Vectorizing sequence data...\"\n",
    "tokenizer = Tokenizer(nb_words=max_words)\n",
    "tokenizer.fit_on_texts(X_seq, unknown_words=True)\n",
    "X_seq = tokenizer.texts_to_sequences(X_seq, replace=True)\n",
    "\n",
    "print \"Divide train and test\"\n",
    "y_train = []\n",
    "x_train = []\n",
    "maxlen = 50\n",
    "\n",
    "for s in X_seq:\n",
    "    if len(s) < 3 or len(s)>maxlen:\n",
    "        continue        \n",
    "    x_train.append(s)\n",
    "    y_train.append(s[::-1])\n",
    "\n",
    "\n",
    "#Y_train = np_utils.to_categorical(y_train, max_words)\n",
    "    \n",
    "cut = int(len(X_seq)*0.8)\n",
    "X_test = x_train[cut:]\n",
    "X_train = x_train[:cut]\n",
    "Y_test = y_train[cut:]\n",
    "Y_train = y_train[:cut]\n",
    "    \n",
    "print \"Pad sequences (samples x time)\"\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "Y_train = sequence.pad_sequences(Y_train, maxlen=maxlen)\n",
    "Y_test = sequence.pad_sequences(Y_test, maxlen=maxlen)\n",
    "\n",
    "print 'X_train shape:', X_train.shape\n",
    "print 'X_test shape:', X_test.shape\n",
    "\n",
    "#print \"Convert class vector to binary class matrix (for use with categorical_crossentropy)\"\n",
    "#Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "#Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "#print 'Y_train shape:', Y_train.shape\n",
    "#print 'Y_test shape:', Y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "voc_dic = tokenizer.word_index.items()\n",
    "voc_dic.sort(key = lambda x: x[1])\n",
    "voc = [x[0] for x in voc_dic]\n",
    "inv_dic = {v:k for (k,v) in voc_dic}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "voc = np.asarray(voc)\n",
    "np.savez_compressed('dataset',x_train=X_train,x_test=X_test,y_train=Y_train,y_test=Y_test,voc=voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.load('dataset.npz')\n",
    "print x.files\n",
    "voc = x['voc'].tolist()\n",
    "voc_dic = dict(zip(voc, range(len(voc))))\n",
    "inv_dic = {v:k for (k,v) in voc_dic.items()}\n",
    "X_train, X_test, Y_train, Y_test = x['x_train'],x['x_test'],x['y_train'],x['y_test']\n",
    "max_words = max(np.max(X_train), np.max(X_test))+1\n",
    "print max_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_features= max_words\n",
    "emb_size = 256\n",
    "lstm_size = 128\n",
    "batch_size = 16\n",
    "max_size = X_train.shape[1]\n",
    "\n",
    "print 'Build model...'\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, emb_size))\n",
    "model.add(LSTM(emb_size, lstm_size)) # try using a GRU instead, for fun\n",
    "model.add(RepeatVector(max_size))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(LSTM(lstm_size, lstm_size, return_sequences=True))\n",
    "model.add(SharedDense(lstm_size, max_features, activation='softmax'))\n",
    "optimizer = SGD(lr=0.7/batch_size)\n",
    "\n",
    "model.compile(loss='categorical_scalar_crossentropy', optimizer=optimizer)\n",
    "# try using different optimizers and different optimizer configs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "print \"Train...\"\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=10, verbose=0)\n",
    "score = model.evaluate(X_test, Y_test, batch_size=batch_size)\n",
    "print 'Test score:', score\n",
    "\n",
    "classes = model.predict_classes(X_test, batch_size=batch_size)\n",
    "acc = np_utils.accuracy(classes, Y_test)\n",
    "print 'Test accuracy:', acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tostr(u):\n",
    "    st = \"\"\n",
    "    for x in u:\n",
    "        st+=inv_dic[x]+\" \"\n",
    "    return st.strip()\n",
    "\n",
    "def see(X, Y):\n",
    "    for x,y in zip (X,Y):\n",
    "        print tostr(x), \" / \", tostr(y)\n",
    "\n",
    "def seeModel(X, model):\n",
    "    see(X, model.predict_classes(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seeModel(X_test[0:20], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#x = model._predict(X_test[0:16])\n",
    "x = model.predict_proba(X_test[0:16], batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.predict_classes(X_test[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tostr(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(16,) + x[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
